{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns  #Plots\n",
    "from matplotlib import rcParams  #Size of plots  \n",
    "%matplotlib inline\n",
    "import pickle #to save the model\n",
    "import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_22_df = pd.read_parquet('Train/yellow_tripdata_2022-01.parquet')\n",
    "Feb_22_df = pd.read_parquet('Train/yellow_tripdata_2022-02.parquet')\n",
    "Mar_22_df = pd.read_parquet('Train/yellow_tripdata_2022-03.parquet')\n",
    "\n",
    "Jan_23_df = pd.read_parquet('Test/yellow_tripdata_2023-01.parquet')\n",
    "Feb_23_df = pd.read_parquet('Test/yellow_tripdata_2023-02.parquet')\n",
    "Mar_23_df = pd.read_parquet('Test/yellow_tripdata_2023-03.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Time stamps to UNIX time stamp format\n",
    "# \"YYYY-MM-DD HH:MM:SS\" into unix time stamp\n",
    "\n",
    "def convert_to_unix(s):\n",
    "    s = str(s)\n",
    "    return time.mktime(datetime.datetime.strptime(s, \"%Y-%m-%dT%H:%M:%S.%f\").timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we return a data frame which contains the columns\n",
    "# 1.'passenger_count' : self explanatory\n",
    "# 2.'trip_distance' : self explanatory\n",
    "# 7.'total_amount' : total fair that was paid\n",
    "# 8.'trip_times' : duration of each trip\n",
    "# 9.'pickup_times : pickup time converted into unix time \n",
    "\n",
    "# 10.'Speed' : velocity of each trip\n",
    "def return_with_trip_times(month):\n",
    "    duration = month[['tpep_pickup_datetime','tpep_dropoff_datetime']]\n",
    "    #pickups and dropoffs to unix time\n",
    "    duration_pickup = [convert_to_unix(x) for x in duration['tpep_pickup_datetime'].values]\n",
    "    duration_drop = [convert_to_unix(x) for x in duration['tpep_dropoff_datetime'].values]\n",
    "    #calculate duration of trips in minutes\n",
    "    durations = (np.array(duration_drop) - np.array(duration_pickup))/float(60)\n",
    "\n",
    "    #append durations of trips and speed in miles/hr to a new dataframe\n",
    "    new_frame = month[['passenger_count','trip_distance','PULocationID','DOLocationID','total_amount']]\n",
    "    \n",
    "    new_frame['trip_times'] = durations\n",
    "    new_frame['pickup_times'] = duration_pickup\n",
    "    new_frame['Speed'] = 60*(new_frame['trip_distance']/new_frame['trip_times'])\n",
    "    \n",
    "    return new_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "    'trip_times_min': 1,\n",
    "    'trip_times_max': 800,\n",
    "    'trip_distance_min': 0,\n",
    "    'trip_distance_max': 26.4,\n",
    "    'speed_min': 0,\n",
    "    'speed_max': 48.32,\n",
    "    'fare_min': 0,\n",
    "    'fare_max': 97.6,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Removal Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all outliers based on our univariate analysis\n",
    "def remove_outliers(new_frame, thresholds):\n",
    "    a = new_frame.shape[0]\n",
    "    \n",
    "    temp_frame = new_frame[(new_frame.trip_times > thresholds['trip_times_min']) & (new_frame.trip_times < thresholds['trip_times_max'])]\n",
    "    b = temp_frame.shape[0]\n",
    "    print (\"Number of outliers from trip times analysis:\", (a - b))\n",
    "    \n",
    "    temp_frame = new_frame[(new_frame.trip_distance > thresholds['trip_distance_min']) & (new_frame.trip_distance < thresholds['trip_distance_max'])]\n",
    "    c = temp_frame.shape[0]\n",
    "    print (\"Number of outliers from trip distance analysis:\", (a - c))\n",
    "    \n",
    "    temp_frame = new_frame[(new_frame.Speed <= thresholds['speed_max']) & (new_frame.Speed >= thresholds['speed_min'])]\n",
    "    d = temp_frame.shape[0]\n",
    "    print (\"Number of outliers from speed analysis:\", (a - d))\n",
    "    \n",
    "    temp_frame = new_frame[(new_frame.total_amount < thresholds['fare_max']) & (new_frame.total_amount > thresholds['fare_min'])]\n",
    "    e = temp_frame.shape[0]\n",
    "    print (\"Number of outliers from fare analysis:\", (a - e))\n",
    "    \n",
    "    \n",
    "    new_frame = new_frame[(new_frame.trip_times > thresholds['trip_times_min']) & (new_frame.trip_times < thresholds['trip_times_max'])]\n",
    "    new_frame = new_frame[(new_frame.trip_distance > thresholds['trip_distance_min']) & (new_frame.trip_distance < thresholds['trip_distance_max'])]\n",
    "    new_frame = new_frame[(new_frame.Speed < thresholds['speed_max']) & (new_frame.Speed > thresholds['speed_min'])]\n",
    "    new_frame = new_frame[(new_frame.total_amount < thresholds['fare_max']) & (new_frame.total_amount > thresholds['fare_min'])]\n",
    "    \n",
    "    print (\"Total outliers removed:\", (a - new_frame.shape[0]))\n",
    "    print (\"---\")\n",
    "    return new_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refer:https://www.unixtimestamp.com/\n",
    "# 1640975400 : 2022-01-01 00:00:00 \n",
    "# 1643653800 : 2022-02-01 00:00:00 \n",
    "# 1646073000 : 2022-03-01 00:00:00\n",
    "\n",
    "# 1672511400 : 2023-01-01 00:00:00 \n",
    "# 1675189800 : 2023-02-01 00:00:00 \n",
    "# 1677609000 : 2023-03-01 00:00:00\n",
    "\n",
    "def add_pickup_bins(frame, month, year):\n",
    "    \"\"\"\n",
    "    Adds pickup bins to the given DataFrame based on the provided month and year.\n",
    "\n",
    "    Args:\n",
    "        frame (DataFrame): The DataFrame to which pickup bins will be added.\n",
    "        month (int): The month for which pickup bins will be calculated.\n",
    "        year (int): The year for which pickup bins will be calculated.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The updated DataFrame with pickup bins added.\n",
    "    \"\"\"\n",
    "    unix_pickup_times = [i for i in frame['pickup_times'].values]\n",
    "    unix_times = [[1640975400, 1643653800, 1646073000], \\\n",
    "                  [1672511400, 1675189800, 1677609000]]\n",
    "\n",
    "    start_pickup_unix = unix_times[year - 2022][month - 1]\n",
    "    tenminutewise_binned_unix_pickup_times = [(int((i - start_pickup_unix) / 600)) for i in unix_pickup_times]\n",
    "    frame['pickup_bins'] = np.array(tenminutewise_binned_unix_pickup_times)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preproc(month, monthname, monthnum, year):\n",
    "    \"\"\"\n",
    "    Preprocesses the data for a given month.\n",
    "\n",
    "    Parameters:\n",
    "    - month (str): The name of the month.\n",
    "    - monthname (str): The full name of the month.\n",
    "    - monthnum (int): The numerical representation of the month.\n",
    "    - year (int): The year.\n",
    "\n",
    "    Returns:\n",
    "    - frame (DataFrame): The preprocessed data frame.\n",
    "    \"\"\"\n",
    "    frame_with_duration = return_with_trip_times(month)\n",
    "    print(\"Removing outliers in the month of\", monthname)\n",
    "    print(\"----\")\n",
    "    frame_with_durations_outliers_removed = remove_outliers(frame_with_duration, thresholds)\n",
    "    print(\"Fraction of data points that remain after removing outliers:\", float(len(frame_with_durations_outliers_removed)) / len(frame_with_duration))\n",
    "\n",
    "    frame = add_pickup_bins(frame_with_durations_outliers_removed, monthnum, year)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_groupby(frame):\n",
    "    \"\"\"\n",
    "    Groups the given DataFrame by 'PULocationID' and 'pickup_bins' columns,\n",
    "    and counts the number of occurrences of 'trip_distance' for each group.\n",
    "\n",
    "    Args:\n",
    "        frame (DataFrame): The input DataFrame containing the data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The grouped DataFrame with the no of pickups for each group.\n",
    "    \"\"\"\n",
    "    frame_groupby = frame[['PULocationID','pickup_bins','trip_distance']].groupby(['PULocationID','pickup_bins']).count().rename(columns={'trip_distance': 'no of pickups'})\n",
    "    return frame_groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing outliers in the month of Jan_22\n",
      "----\n",
      "Number of outliers from trip times analysis: 32812\n",
      "Number of outliers from trip distance analysis: 32892\n",
      "Number of outliers from speed analysis: 8009\n",
      "Number of outliers from fare analysis: 18702\n",
      "Total outliers removed: 61612\n",
      "---\n",
      "Fraction of data points that remain after removing outliers: 0.9749944296329727\n",
      "Removing outliers in the month of Feb_22\n",
      "----\n",
      "Number of outliers from trip times analysis: 37152\n",
      "Number of outliers from trip distance analysis: 36016\n",
      "Number of outliers from speed analysis: 8109\n",
      "Number of outliers from fare analysis: 22240\n",
      "Total outliers removed: 69608\n",
      "---\n",
      "Fraction of data points that remain after removing outliers: 0.9766371498450543\n",
      "Removing outliers in the month of Mar_22\n",
      "----\n",
      "Number of outliers from trip times analysis: 48393\n",
      "Number of outliers from trip distance analysis: 46785\n",
      "Number of outliers from speed analysis: 10174\n",
      "Number of outliers from fare analysis: 31153\n",
      "Total outliers removed: 91277\n",
      "---\n",
      "Fraction of data points that remain after removing outliers: 0.974840140886611\n",
      "Removing outliers in the month of Jan_23\n",
      "----\n",
      "Number of outliers from trip times analysis: 36158\n",
      "Number of outliers from trip distance analysis: 51136\n",
      "Number of outliers from speed analysis: 4909\n",
      "Number of outliers from fare analysis: 86185\n",
      "Total outliers removed: 138495\n",
      "---\n",
      "Fraction of data points that remain after removing outliers: 0.9548400497462147\n",
      "Removing outliers in the month of Feb_23\n",
      "----\n",
      "Number of outliers from trip times analysis: 34580\n",
      "Number of outliers from trip distance analysis: 45995\n",
      "Number of outliers from speed analysis: 4759\n",
      "Number of outliers from fare analysis: 80422\n",
      "Total outliers removed: 128577\n",
      "---\n",
      "Fraction of data points that remain after removing outliers: 0.9558754339034062\n",
      "Removing outliers in the month of Mar_23\n",
      "----\n",
      "Number of outliers from trip times analysis: 41714\n",
      "Number of outliers from trip distance analysis: 55126\n",
      "Number of outliers from speed analysis: 5501\n",
      "Number of outliers from fare analysis: 103070\n",
      "Total outliers removed: 160156\n",
      "---\n",
      "Fraction of data points that remain after removing outliers: 0.9529474117786005\n"
     ]
    }
   ],
   "source": [
    "Jan_22_df_proc = data_preproc(Jan_22_df,'Jan_22',1,2022)\n",
    "Feb_22_df_proc = data_preproc(Feb_22_df,'Feb_22',2,2022)\n",
    "Mar_22_df_proc = data_preproc(Mar_22_df,'Mar_22',3,2022)\n",
    "\n",
    "Jan_23_df_proc = data_preproc(Jan_23_df,'Jan_23',1,2023)\n",
    "Feb_23_df_proc = data_preproc(Feb_23_df,'Feb_23',2,2023)\n",
    "Mar_23_df_proc = data_preproc(Mar_23_df,'Mar_23',3,2023)\n",
    "\n",
    "Jan_22_df_grpby = frame_groupby(Jan_22_df_proc)\n",
    "Feb_22_df_grpby = frame_groupby(Feb_22_df_proc)\n",
    "Mar_22_df_grpby = frame_groupby(Mar_22_df_proc)\n",
    "\n",
    "Jan_23_df_grpby = frame_groupby(Jan_23_df_proc)\n",
    "Feb_23_df_grpby = frame_groupby(Feb_23_df_proc)\n",
    "Mar_23_df_grpby = frame_groupby(Mar_23_df_proc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Processed Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open('3_month_data_2022.pkl', 'wb') \n",
    "\n",
    "# source, destination \n",
    "pickle.dump(Jan_22_df_proc, pickle_file)\n",
    "pickle.dump(Jan_22_df_grpby, pickle_file)\n",
    "pickle.dump(Feb_22_df_proc, pickle_file)\n",
    "pickle.dump(Feb_22_df_grpby, pickle_file)\n",
    "pickle.dump(Mar_22_df_proc, pickle_file)\n",
    "pickle.dump(Mar_22_df_grpby, pickle_file)\n",
    "pickle_file.close()\n",
    "\n",
    "pickle_file = open('3_month_data_2023.pkl', 'wb') \n",
    "\n",
    "# source, destination \n",
    "pickle.dump(Jan_23_df_proc, pickle_file)\n",
    "pickle.dump(Jan_23_df_grpby, pickle_file)\n",
    "pickle.dump(Feb_23_df_proc, pickle_file)\n",
    "pickle.dump(Feb_23_df_grpby, pickle_file)\n",
    "pickle.dump(Mar_23_df_proc, pickle_file)\n",
    "pickle.dump(Mar_23_df_grpby, pickle_file)\n",
    "pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
